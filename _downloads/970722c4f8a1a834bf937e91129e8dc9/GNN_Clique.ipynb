{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Main file clique\n\nThis is the main file for the clique classification task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\nimport numpy as np\nimport gnn_gnn_utils\nimport GNN as GNN\nimport Net_Clique as n\nimport tensorflow as tf\nimport os\nimport pandas as pd\nfrom scipy.sparse import coo_matrix\nfrom sklearn.preprocessing import StandardScaler\n\n\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\ndata_path = \"./data\"\n\n############# training set ##########\n\nset_name = \"cli_15_7_200\"\n############# training set ################\n\n\n#inp, arcnode, nodegraph, nodein, labels = Library.set_load_subgraph(data_path, \"train\")\ninp, arcnode, nodegraph, nodein, labels, _ = gnn_utils.set_load_general(data_path, \"train\", set_name=set_name)\n############ test set ####################\n\n#inp_test, arcnode_test, nodegraph_test, nodein_test, labels_test = Library.set_load_subgraph(data_path, \"test\")\ninp_test, arcnode_test, nodegraph_test, nodein_test, labels_test, _ = gnn_utils.set_load_general(data_path, \"test\", set_name=set_name)\n\n############ validation set #############\n\n#inp_val, arcnode_val, nodegraph_val, nodein_val, labels_val = Library.set_load_subgraph(data_path, \"valid\")\ninp_val, arcnode_val, nodegraph_val, nodein_val, labels_val, _ = gnn_utils.set_load_general(data_path, \"validation\", set_name=set_name)\n\n# set threshold, learning rate and state dimension\nthreshold = 0.001\nlearning_rate = 0.0001\nstate_dim = 5\n\n# set input and output dim, the maximum number of iterations, the number of epochs and the optimizer\ntf.reset_default_graph()\n\ninput_dim = len(inp[0][0])\noutput_dim = 2\nmax_it = 50\nnum_epoch = 5000\noptimizer = tf.train.AdamOptimizer\n\n\n\n\n\n# initialize state and output network\nnet = n.Net(input_dim, state_dim, output_dim)\n\n# initialize GNN\nparam = \"st_d\" + str(state_dim) + \"_th\" + str(threshold) + \"_lr\" + str(learning_rate)\nprint(param)\ng = GNN.GNN(net, max_it=max_it, input_dim=input_dim, output_dim=output_dim, state_dim=state_dim, optimizer=optimizer, learning_rate=learning_rate, threshold=threshold, param=param)\ncount = 0\n\n# train the model and validate every 30 epochs\nfor j in range(0, num_epoch):\n    g.Train(inp[0], arcnode[0], labels, count, nodegraph[0])\n\n    if count % 30 == 0:\n        print(g.Validate(inp_val[0], arcnode_val[0], labels_val, count, nodegraph_val[0]))\n\n    count = count + 1\n\n# evaluate on the test set\nprint(g.Evaluate(inp_test[0], arcnode_test[0], labels_test, nodegraph_test[0]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}