{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nUtils\n=====\n\nCommon utilities for data loading and preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport scipy.io as sio\nimport os\nfrom scipy.sparse import coo_matrix\nfrom collections import namedtuple\nimport scipy.sparse as sp\nSparseMatrix = namedtuple(\"SparseMatrix\", \"indices values dense_shape\")\n\ndef GetInput(mat, lab, batch=1, grafi=None):\n    \"\"\"grafi is vector with same cardinaluty of nodes, denoting to which graph\n        belongs each node\n    \"\"\"\n    # numero di batch\n    batch_number = grafi.max() // batch   # if only one graph => grafi.max() is 0 => batch_number == 0\n    # dataframe containing adjacency matrix\n    dmat = pd.DataFrame(mat, columns=[\"id_1\", \"id_2\"])\n    # dataframe containing labels each node\n    dlab = pd.DataFrame(lab, columns=[\"lab\" + str(i) for i in range(0, lab.shape[1])])\n    # darch=pd.DataFrame(arc, columns=[\"arch\"+str(i) for i in range(0,arc.shape[1])])\n    # dataframe denoting graph belonging each node\n    dgr = pd.DataFrame(grafi, columns=[\"graph\"])\n\n    # creating input : id_p, id_c, label_p, label_c, graph_belong\n    dresult = dmat\n    dresult = pd.merge(dresult, dlab, left_on=\"id_1\", right_index=True, how='left')\n    dresult = pd.merge(dresult, dlab, left_on=\"id_2\", right_index=True, how='left')\n    # dresult=pd.concat([dresult, darch], axis=1)\n    dresult = pd.merge(dresult, dgr, left_on=\"id_1\", right_index=True, how='left')\n\n    data_batch = []\n    arcnode_batch = []\n    nodegraph_batch = []\n    node_in = []\n    # creating batch data => for each batch, redefining the id so that they start from 0 index\n    for i in range(0, batch_number + 1):\n\n        # getting minimum index of the current batch\n        grafo_indexMin = (i * batch)\n        grafo_indexMax = (i * batch) + batch\n\n        adj = dresult.loc[(dresult[\"graph\"] >= grafo_indexMin) & (dresult[\"graph\"] < grafo_indexMax)]\n        min_id = adj[[\"id_1\", \"id_2\"]].min(axis=0).min()\n\n        #start from 0 index for the new batch\n        adj[\"id_1\"] = adj[\"id_1\"] - min_id\n        adj[\"id_2\"] = adj[\"id_2\"] - min_id\n\n        min_gr = adj[\"graph\"].min()\n        adj[\"graph\"] = adj[\"graph\"] - min_gr\n\n        # append values to batches : id_2, lab0_1, lab1_1, lab0_2, lab1_2 (excluded first and last - id_p and graph_id)\n        data_batch.append(adj.values[:, :-1])\n\n        # arcMat creation\n\n        # max_id of nodes in the current batch\n        max_id = int(adj[[\"id_1\", \"id_2\"]].max(axis=0).max())\n\n        max_gr = int(adj[\"graph\"].max())\n\n        # getting ids of nodes (p and c)\n        mt = adj[[\"id_1\", \"id_2\"]].values\n        # arcnode matrix : first shape same as arcs, second same as nodes in the batch\n        arcnode = np.zeros((mt.shape[0], max_id + 1))\n\n        # arcnode: state of parent node = sum (h(state of all the neighbors ,..) (of the parent node)\n        # => sum contributes of all the arcs involving the parent\n        # in j-th arc (row) => put one in the position corresponding to the parent node's column\n        # => found in the adjacnecy matrix in j-th row, 1 st position\n\n        # for j in range(0, mt.shape[0]):\n        #     arcnode[j][mt[j][0]] = 1\n\n        arcnode = SparseMatrix(indices=np.stack((mt[:, 0], np.arange(len(mt))), axis=1), values=np.ones([len(mt)]),\n                               dense_shape=[max_id + 1, len(mt)])\n\n        arcnode_batch.append(arcnode)\n\n        # nodegraph\n        nodegraph = np.zeros((max_id + 1, max_gr + 1))\n\n        for t in range(0, max_id + 1):\n            val = adj[[\"graph\"]].loc[(adj[\"id_1\"] == t) | (adj[\"id_2\"] == t)].values[0]\n            nodegraph[t][val] = 1\n\n        nodegraph_batch.append(nodegraph)\n        # node number in each graph\n        grbtc = dgr.loc[(dgr[\"graph\"] >= grafo_indexMin) & (dgr[\"graph\"] < grafo_indexMax)]\n        #counting number nodes in current batch\n        node_in.append(grbtc.groupby([\"graph\"]).size().values)\n\n    return data_batch, arcnode_batch, nodegraph_batch, node_in\n\n\ndef set_load_subgraph(data_path, set_type):\n    # load adjacency list\n    types = [\"train\", \"valid\", \"test\"]\n    try:\n        if set_type not in types:\n            raise NameError('Wrong set name!')\n\n        # load adjacency list\n        mat = sio.loadmat(os.path.join(data_path, 'conmat{}.mat'.format(set_type)))\n        # load adiacenyc matrixc in sparse format\n        adj = coo_matrix(mat[\"conmat_{}set\".format(set_type)].T)\n        adj = np.array([adj.row, adj.col]).T\n\n        # load node label\n        mat = sio.loadmat(os.path.join(data_path, \"nodelab{}.mat\".format(set_type)))\n        lab = np.asarray(mat[\"nodelab_{}set\".format(set_type)]).T\n\n        # load target and convert to one-hot encoding\n        mat = sio.loadmat(os.path.join(data_path, \"tar{}.mat\".format(set_type)))\n        target = np.asarray(mat[\"target_{}set\".format(set_type)]).T\n        # one-hot encoding of targets\n        labels = pd.get_dummies(pd.Series(target.reshape(-1)))\n        labels = labels.values\n        # compute inputs and arcnode\n        inp, arcnode, nodegraph, nodein = GetInput(adj, lab, 1, np.zeros(len(labels), dtype=int)) # last argument: graph to which each node belongs\n        return inp, arcnode, nodegraph, nodein, labels, lab\n\n    except Exception as e:\n        print(\"Caught exception: \", e)\n        exit(1)\n\ndef set_load_clique(data_path, set_type):\n    import load as ld\n    # load adjacency list\n    types = [\"train\", \"validation\", \"test\"]\n    train = ld.loadmat(os.path.join(data_path, \"cliquedataset.mat\"))\n    train = train[\"dataSet\"]\n    try:\n        if set_type not in types:\n            raise NameError('Wrong set name!')\n\n        # load adjacency list\n        # take adjacency list\n        adj = coo_matrix(train['{}Set'.format(set_type)]['connMatrix'].T)\n        adj = np.array([adj.row, adj.col]).T\n\n        # take node labels\n        lab = np.asarray(train['{}Set'.format(set_type)]['nodeLabels']).T\n\n        # take targets and convert to one-hot encoding\n        target = np.asarray(train['{}Set'.format(set_type)]['targets']).T\n        labels = pd.get_dummies(pd.Series(target))\n        labels = labels.values\n\n        # compute inputs and arcnode\n        get_lab = lab.reshape(lab.shape[0], 1) if set_type == \"train\" else lab.reshape(len(labels), 1)\n        inp, arcnode, nodegraph, nodein = GetInput(adj, get_lab, 1,\n                                                           np.zeros(len(labels), dtype=int))\n        return inp, arcnode, nodegraph, nodein, labels\n\n    except Exception as e:\n        print(\"Caught exception: \", e)\n        exit(1)\n\n\ndef set_load_mutag(set_type, train):\n    # load adjacency list\n    types = [\"train\", \"validation\", \"test\"]\n    try:\n        if set_type not in types:\n            raise NameError('Wrong set name!')\n\n            ############ training set #############\n\n            # take adjacency list\n        adj = coo_matrix(train['{}Set'.format(set_type)]['connMatrix'])\n        adj = np.array([adj.row, adj.col]).T\n\n        # take node labels\n        lab = np.asarray(train['{}Set'.format(set_type)]['nodeLabels']).T\n        mask = coo_matrix(train['{}Set'.format(set_type)][\"maskMatrix\"])\n\n        # take target, generate output for each graph, and convert to one-hot encoding\n        target = np.asarray(train['{}Set'.format(set_type)]['targets']).T\n        v = mask.col\n        target = np.asarray([target[x] for x in v])\n        # target = target[target != 0] # equivalent code\n        labels = pd.get_dummies(pd.Series(target))\n        labels = labels.values\n\n        # build graph indices\n        gr = np.array(mask.col)\n        indicator = []\n        for j in range(0, len(gr) - 1):\n            for i in range(gr[j], gr[j + 1]):\n                indicator.append(j)\n        for i in range(gr[-1], adj.max() + 1):\n            indicator.append(len(gr) - 1)\n        indicator = np.asarray(indicator)\n\n        # take input, arcnode matrix, nodegraph matrix\n        inp, arcnode, nodegraph, nodein = GetInput(adj, lab, indicator.max() + 1, indicator)\n\n        return inp, arcnode, nodegraph, nodein, labels\n\n    except Exception as e:\n        print(\"Caught exception: \", e)\n        exit(1)\n\n\ndef set_load_general(data_path, set_type, set_name=\"sub_30_15\"):\n    import load as ld\n    # load adjacency list\n    types = [\"train\", \"validation\", \"test\"]\n    train = ld.loadmat(os.path.join(data_path, \"{}.mat\".format(set_name)))\n    train = train[\"dataSet\"]\n    try:\n        if set_type not in types:\n            raise NameError('Wrong set name!')\n\n        # load adjacency list\n        # take adjacency list\n        adj = coo_matrix(train['{}Set'.format(set_type)]['connMatrix'].T)\n        adj = np.array([adj.row, adj.col]).T\n\n        # take node labels\n        lab = np.asarray(train['{}Set'.format(set_type)]['nodeLabels']).T\n\n        # if clique (labels with only one dimension\n        if len(lab.shape) < 2:\n            lab = lab.reshape(lab.shape[0], 1)\n\n        # take targets and convert to one-hot encoding\n        target = np.asarray(train['{}Set'.format(set_type)]['targets']).T\n        labels = pd.get_dummies(pd.Series(target))\n        labels = labels.values\n\n        # compute inputs and arcnode\n\n        inp, arcnode, nodegraph, nodein = GetInput(adj, lab, 1,\n                                                           np.zeros(len(labels), dtype=int))\n        return inp, arcnode, nodegraph, nodein, labels, lab\n\n    except Exception as e:\n        print(\"Caught exception: \", e)\n        exit(1)\n\n\n\n\ndef load_karate(path=\"data/karate-club/\"):\n    \"\"\"Load karate club dataset\"\"\"\n    print('Loading karate club dataset...')\n\n    edges = np.loadtxt(\"{}edges.txt\".format(path), dtype=np.int32) - 1  # 0-based indexing\n    edges = edges[np.lexsort((edges[:, 1], edges[:, 0]))]  # reorder list of edges also by second column\n    features = sp.eye(np.max(edges+1), dtype=np.float32).tocsr()\n    idx_labels = np.loadtxt(\"{}mod-based-clusters.txt\".format(path), dtype=np.int32)\n    idx_labels = idx_labels[idx_labels[:, 0].argsort()]\n\n    labels = np.eye(max(idx_labels[:, 1])+1, dtype=np.int32)[idx_labels[:, 1]]  # one-hot encoding of labels\n\n    E = np.concatenate((edges, np.zeros((len(edges), 1), dtype=np.int32)), axis=1)\n    N = np.concatenate((features.toarray(), np.zeros((features.shape[0], 1), dtype=np.int32)), axis=1)\n\n    return E, N, labels,\n\n\ndef from_EN_to_GNN(E, N):\n    \"\"\"\n    :param E: # E matrix - matrix of edges : [[id_p, id_c, graph_id],...]\n    :param N: # N matrix - [node_features, graph_id (to which the node belongs)]\n    :return: # L matrix - list of graph targets [tar_g_1, tar_g_2, ...]\n    \"\"\"\n    N_full = N\n    N = N[:, :-1]  # avoid graph_id\n    e = E[:, :2]  # take only first tow columns => id_p, id_c\n    feat_temp = np.take(N, e, axis=0)  # take id_p and id_c  => (n_archs, 2, label_dim)\n    feat = np.reshape(feat_temp, [len(E), -1])  # (n_archs, 2*label_dim) => [[label_p, label_c], ...]\n    # creating input for gnn => [id_p, id_c, label_p, label_c]\n    inp = np.concatenate((E[:, 1:2], feat), axis=1)\n    # creating arcnode matrix, but transposed\n    \"\"\"\n    1 1 0 0 0 0 0 \n    0 0 1 1 0 0 0\n    0 0 0 0 1 1 1    \n\n    \"\"\"  # for the indices where to insert the ones, stack the id_p and the column id (single 1 for column)\n    arcnode = SparseMatrix(indices=np.stack((E[:, 0], np.arange(len(E))), axis=1),\n                           values=np.ones([len(E)]).astype(np.float32),\n                           dense_shape=[len(N), len(E)])\n\n    # get the number of graphs => from the graph_id\n    num_graphs = int(max(N_full[:, -1]) + 1)\n    # get all graph_ids\n    g_ids = N_full[:, -1]\n    g_ids = g_ids.astype(np.int32)\n\n    # creating graphnode matrix => create identity matrix get row corresponding to id of the graph\n    # graphnode = np.take(np.eye(num_graphs), g_ids, axis=0).T\n    # substitued with same code as before\n    graphnode = SparseMatrix(indices=np.stack((g_ids, np.arange(len(g_ids))), axis=1),\n                             values=np.ones([len(g_ids)]).astype(np.float32),\n                             dense_shape=[num_graphs, len(N)])\n\n    # print(graphnode.shape)\n\n    return inp, arcnode, graphnode"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}