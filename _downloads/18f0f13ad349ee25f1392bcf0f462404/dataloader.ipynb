{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# General Dataloder\n\nThis is the dataloader file for the PyTorch implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom abc import abstractmethod\nfrom torch.utils.data import DataLoader\nimport torch\nfrom torchvision import datasets, transforms\nimport networkx as nx\nimport typing\nimport scipy\nimport scipy.io as spio\nimport numpy as np\nimport os\n\n\ndef loadmat(filename):\n    '''\n    this function should be called instead of direct spio.loadmat\n    as it cures the problem of not properly recovering python dictionaries\n    from mat files. It calls the function check keys to cure all entries\n    which are still mat-objects\n    '''\n\n    def _check_keys(d):\n        '''\n        checks if entries in dictionary are mat-objects. If yes\n        todict is called to change them to nested dictionaries\n        '''\n        for key in d:\n            if isinstance(d[key], spio.matlab.mio5_params.mat_struct):\n                d[key] = _todict(d[key])\n        return d\n\n    def _todict(matobj):\n        '''\n        A recursive function which constructs from matobjects nested dictionaries\n        '''\n        d = {}\n        for strg in matobj._fieldnames:\n            elem = matobj.__dict__[strg]\n            if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n                d[strg] = _todict(elem)\n            elif isinstance(elem, np.ndarray):\n                d[strg] = _tolist(elem)\n            else:\n                d[strg] = elem\n        return d\n\n    def _tolist(ndarray):\n        '''\n        A recursive function which constructs lists from cellarrays\n        (which are loaded as numpy ndarrays), recursing into the elements\n        if they contain matobjects.\n        '''\n        elem_list = []\n        for sub_elem in ndarray:\n            if isinstance(sub_elem, spio.matlab.mio5_params.mat_struct):\n                elem_list.append(_todict(sub_elem))\n            elif isinstance(sub_elem, np.ndarray):\n                elem_list.append(_tolist(sub_elem))\n            else:\n                elem_list.append(sub_elem)\n        return elem_list\n\n    data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n    return _check_keys(data)\n\n\n# train = loadmat('multi1')\n\n# thanks Pedro H. Avelar\ndef nx_to_format(G, aggregation_type, sparse_matrix=True):\n    e = len(G.edges)\n    n = len(G.nodes)\n\n    # edges = torch.LongTensor(list(G.edges))\n    edg = sorted(list(G.edges))\n    edges = torch.LongTensor(edg)\n\n    adj_matrix = np.asarray(nx.to_numpy_matrix(G))\n\n    if aggregation_type == \"sum\":\n        pass\n    elif aggregation_type == \"degreenorm\":\n        row_sum = np.sum(adj_matrix, axis=0, keepdims=True)\n        adj_matrix = adj_matrix / row_sum\n    elif aggregation_type == \"symdegreenorm\":\n        raise NotImplementedError(\"Symmetric degree normalization not yet implemented\")\n    else:\n        raise ValueError(\"Invalid neighbour aggregation type\")\n\n    if sparse_matrix:\n        agg_matrix_i = torch.LongTensor([[s for s, t in G.edges], list(range(e))])\n        agg_matrix_v = torch.FloatTensor([adj_matrix[s, t] for s, t in G.edges])\n        agg_matrix = torch.sparse.FloatTensor(agg_matrix_i, agg_matrix_v, torch.Size([n, e]))\n    else:\n        agg_matrix = torch.zeros(*[n, e])\n        for i, (s, t) in enumerate(edg):\n            agg_matrix[s, i] = adj_matrix[s, t]\n\n    return edges, agg_matrix\n\n\n\n\nclass Dataset:\n    def __init__(\n            self,\n            name,\n            num_nodes,\n            num_edges,\n            label_dim,\n            is_multiclass,\n            num_classes,\n            edges,\n            agg_matrix,\n            node_labels,\n            targets,\n            idx_train=None,\n            idx_valid=None,\n            idx_test=None,\n            graph_node=None\n    ):\n        self.name = name\n        self.num_nodes = num_nodes\n        self.num_edges = num_edges\n        self.node_label_dim = label_dim\n        self.num_classes = num_classes\n        self.is_multiclass = is_multiclass\n        self.edges = edges\n        self.agg_matrix = agg_matrix\n        self.node_labels = node_labels\n        self.targets = targets\n        self.idx_train = idx_train\n        self.idx_valid = idx_valid\n        self.idx_test = idx_test\n\n    def cuda(self):\n        self.edges, self.agg_matrix, self.node_labels, self.targets, self.idx_train, self.idx_test = map(\n            lambda x: x.cuda() if x is not None else None,\n            [self.edges, self.agg_matrix, self.node_labels, self.targets, self.idx_train, self.idx_test]\n        )\n        return self\n\n    def cpu(self):\n        self.edges, self.agg_matrix, self.node_labels, self.targets, self.idx_train, self.idx_test = map(\n            lambda x: x.cuda(),\n            [self.edges, self.agg_matrix, self.node_labels, self.targets, self.idx_train, self.idx_test]\n        )\n        return self\n\n    def to(self, device):\n        if \"cuda\" in device.type:\n            torch.cuda.set_device(device)\n            return self.cuda()\n        else:\n            return self.cpu()\n\n\ndef get_twochains(num_nodes_per_graph=50, pct_labels=.1, pct_valid=.5, aggregation_type=\"sum\", sparse_matrix=True):\n    G1 = nx.generators.classic.path_graph(num_nodes_per_graph)\n    G2 = nx.generators.classic.path_graph(num_nodes_per_graph)\n\n    G = nx.disjoint_union(G1, G2)\n    G = G.to_directed()\n\n    e = len(G.edges)\n    n = len(G.nodes)\n\n    edges, agg_matrix = nx_to_format(G, aggregation_type, sparse_matrix)\n\n    is_multilabel = False\n    n_classes = 2\n    d_l = 1\n    node_labels = torch.zeros(*[n, d_l])\n    # node_labels = torch.eye(n)\n    targets = torch.tensor(np.array(([0] * (n // 2)) + ([1] * (n // 2)), dtype=np.int64), dtype=torch.long)\n\n    idx = np.random.permutation(np.arange(n))\n    idx_trainval = idx[:int(n * pct_labels)]\n    idx_train = torch.LongTensor(idx_trainval[:-int(len(idx_trainval) * pct_valid)])\n    idx_valid = torch.LongTensor(\n        idx_trainval[-int(len(idx_trainval) * pct_valid):])  # TODO wht is he doing, why with BoolTensro is strange?\n    idx_test = torch.LongTensor(idx[int(n * pct_labels):])\n\n    return Dataset(\n        \"twochains\",\n        n,\n        e,\n        d_l,\n        is_multilabel,\n        n_classes,\n        edges,\n        agg_matrix,\n        node_labels,\n        targets,\n        idx_train,\n        idx_valid,\n        idx_test,\n    )\n\n\n############## SSE ################\n\ndef sample_mask(idx, l):\n    \"\"\"Create mask.\"\"\"\n    mask = np.zeros(l)\n    mask[idx] = 1\n    return np.array(mask, dtype=np.bool)\n\n\ndef read_sse_ids(percentage=None, dataset=None):\n    def _internal(file):\n        ids = []\n        with open(os.path.join(dataset, file), 'r') as f:\n            for line in f:\n                ids.append(int(line.strip()))\n        return ids\n\n    if percentage:\n        train_ids = _internal(\n            \"train_idx-{}.txt\".format(\n                percentage))  # list, each element a row of the file => id of the graph belonging to train set\n        test_ids = _internal(\"test_idx-{}.txt\".format(percentage))\n\n    return train_ids, test_ids\n\ndef sample_mask(idx, l):\n    \"\"\"Create mask.\"\"\"\n    mask = np.zeros(l)\n    mask[idx] = 1\n    return np.array(mask, dtype=np.bool)\n\n\ndef get_twochainsSSE(aggregation_type, percentage=0.9, dataset=\"data/n-chains-connect\", node_has_feature=False,\n                     train_file=\"train_idx-\", test_file=\"test_idx-\", sparse_matrix=True):\n    import os\n    print('Loading dataset: {}'.format(dataset))\n    graph_info = \"meta.txt\"\n    neigh = \"adj_list.txt\"\n    labels_file = \"label.txt\"\n    # loading targets\n\n    targets = np.loadtxt(os.path.join(dataset, labels_file))\n    targets = torch.tensor(np.argmax(targets, axis=1), dtype=torch.long)\n\n    with open(os.path.join(dataset, graph_info), 'r') as f:\n        info = f.readline().strip().split()  # (ex. MUTAG - 23 2) number of nodes in the graph, target of the graph\n        if node_has_feature:\n            n_nodes, l, n_feat = [int(w) for w in info]  # n == number of nodes, l label (target) of the graph\n        else:\n            n_nodes, l = [int(w) for w in info]  # n == number of nodes, l label (target) of the graph\n    # load adj_list\n    if node_has_feature:\n        features = np.loadtxt(os.path.join(dataset, \"features.txt\"))\n    else:\n        features = np.zeros((n_nodes, 1), dtype=np.float32)  # zero feature else\n\n    with open(os.path.join(dataset, neigh), 'r') as f:\n\n        g = nx.Graph()  # netxgraph\n        node_features = []\n        # n_edges = 0  # edges in the graph\n        for j in range(n_nodes):\n            # for every row of the current graph  create the graph itself\n            g.add_node(j)  # add node to networkx graph\n\n            row = [int(w) for w in\n                   f.readline().strip().split()]  # composition of each row : number of neighbors, id_neigh_1, id_neigh_2 ...\n            n_edges = row[0]  # increment edge counter with number of neighbors => number of arcs\n            for k in range(1, n_edges + 1):\n                g.add_edge(j, row[k])  # add edge in graph to all nodes from current one\n\n        g = g.to_directed()  # every arc  # in this example, state of\n        # e = [list(pair) for pair in g.edges()]  # [[0, 1], [0, 5], [1, 2], ... list containing lists of edge pair\n\n        edges, agg_matrix = nx_to_format(g, aggregation_type, sparse_matrix)\n        e = len(g.edges)\n        n = len(g.nodes)\n        d_l = 1\n        is_multilabel = False\n        n_classes = 2\n        node_labels = torch.tensor(features, dtype=torch.float)\n        # targets = torch.tensor(np.clip(target, 0, 1), dtype=torch.long)  # convert -1 to 0\n\n        # creation of N matrix - [node_features, graph_id (to which the node belongs)] #here there is a unique graph\n        # create mask for training\n        train_ids, test_ids = read_sse_ids(percentage=percentage, dataset=dataset)\n        # train_mask = sample_mask(train_ids, n)\n        test_ids_temp = range(0, 2000)\n        test_ids = [i for i in test_ids_temp if i not in train_ids]\n        idx_train = torch.LongTensor(train_ids)\n        idx_test = torch.LongTensor(test_ids)\n        idx_valid = torch.LongTensor(test_ids)\n\n        return Dataset(\n            \"two_chainsSSE\",\n            n,\n            e,\n            d_l,\n            is_multilabel,\n            n_classes,\n            edges,\n            agg_matrix,\n            node_labels,\n            targets,\n            idx_train,\n            idx_valid,\n            idx_test,\n        )\n\n\ndef get_subgraph(set=\"sub_10_5_200\", aggregation_type=\"sum\", sparse_matrix=False):\n    from scipy.sparse import coo_matrix\n    import scipy.sparse as sp\n    import pandas as pd\n\n    types = [\"train\", \"validation\", \"test\"]\n    set_name = set\n    train = loadmat(\"./data/subcli/{}.mat\".format(set_name))\n    train = train[\"dataSet\"]\n    dset = {}\n    for set_type in types:\n        adj = coo_matrix(train['{}Set'.format(set_type)]['connMatrix'].T)\n        edges = np.array([adj.row, adj.col]).T\n\n        G = nx.DiGraph()\n        G.add_nodes_from(range(0, np.max(edges) + 1))\n        G.add_edges_from(edges)\n\n        # G = nx.from_edgelist(edges)\n        lab = np.asarray(train['{}Set'.format(set_type)]['nodeLabels']).T\n        if len(lab.shape) < 2:\n            lab = lab.reshape(lab.shape[0], 1)\n        lab = torch.tensor(lab, dtype=torch.float)\n        target = np.asarray(train['{}Set'.format(set_type)]['targets']).T\n        targets = torch.tensor(np.clip(target, 0, 1), dtype=torch.long)  # convert -1 to 0\n\n        edges, agg_matrix = nx_to_format(G, aggregation_type, sparse_matrix)\n\n        e = len(G.edges)\n        n = len(G.nodes)\n        d_l = lab.shape[1]\n        is_multilabel = False\n        n_classes = 2\n        node_labels = lab\n        dset[set_type] = Dataset(\n            \"subgraph_{}\".format(set_type),\n            n,\n            e,\n            d_l,\n            is_multilabel,\n            n_classes,\n            edges,\n            agg_matrix,\n            node_labels,\n            targets)\n\n    return dset\n\n\ndef get_karate(num_nodes_per_graph=None, aggregation_type=\"sum\", sparse_matrix=True):\n    # F = nx.read_edgelist(\"./data/karate/edges.txt\", nodetype=int)\n    G = nx.karate_club_graph()\n\n    # edge = np.loadtxt(\"./data/karate/edges.txt\", dtype=np.int32)   # 0-based indexing\n    # edge_inv = np.flip(edge, axis=1)\n    # edges = np.concatenate((edge, edge_inv))\n    # G = nx.DiGraph()\n    # G.add_edges_from(edges)\n    G = G.to_directed()\n    e = len(G.edges)\n    n = len(G.nodes)\n    # F = nx.Graph()\n    # F.add_edges_from(G.edges)\n\n    edges, agg_matrix = nx_to_format(G, aggregation_type, sparse_matrix=sparse_matrix)\n\n    is_multilabel = False\n    n_classes = 4\n\n    targets = [0] * n\n    # class_nodes = [[]] * n_classes # NB keeps broadcasting also at append time\n    class_nodes = [[], [], [], []]\n    with open(\"./data/karate/classes.txt\") as f:\n        for line in f:\n            node, node_class = map(int, line.split(\" \"))\n            targets[node] = node_class\n            class_nodes[node_class].append(node)\n\n    d_l = n\n    # node_labels = torch.zeros(*[n, d_l])\n    node_labels = torch.eye(n)\n    targets = torch.tensor(targets, dtype=torch.long)\n\n    idx_train = []\n    idx_test = []\n    for c in class_nodes:\n        perm = np.random.permutation(c)\n        idx_train += list(perm[:1])  # first index for training\n        idx_test += list(perm[1:])  # all other indexes for testing\n        # idx_train += list(perm)  # first index for training\n        # idx_test += list(perm)  # all other indexes for testing\n\n    idx_valid = torch.LongTensor(idx_train)\n    idx_train = torch.LongTensor(idx_train)\n    idx_test = torch.LongTensor(idx_test)\n\n    return Dataset(\n        \"karate\",\n        n,\n        e,\n        d_l,\n        is_multilabel,\n        n_classes,\n        edges,\n        agg_matrix,\n        node_labels,\n        targets,\n        idx_train,\n        idx_valid,\n        idx_test,\n    )\n\n\ndef collate(samples):\n    import dgl\n    # The input `samples` is a list of pairs\n    #  (graph, label).\n    graphs, labels = map(list, zip(*samples))\n    batched_graph = dgl.batch(graphs)\n    return batched_graph, torch.tensor(labels)\n\n\ndef get_dgl_minigc(aggregation_type=\"sum\", ):\n    import dgl\n    from dgl.data import MiniGCDataset\n    tr_set = MiniGCDataset(80, 10, 20)\n    test_set = MiniGCDataset(20, 10, 20)\n    data_loader = DataLoader(tr_set, batch_size=80, shuffle=True,\n                             collate_fn=collate)\n    dataiter = iter(data_loader)\n    images, labels = dataiter.next()  # get all the dataset\n    G = images.to_networkx()\n\n    e = len(G.edges)\n    n = len(G.nodes)\n\n    edges, agg_matrix = nx_to_format(G, aggregation_type)\n\n    print(\"ciao\")\n\n\ndef get_dgl_cora(aggregation_type=\"sum\", sparse_matrix=False):\n    import dgl\n    from dgl.data import CoraDataset\n\n    tr_set = CoraDataset()\n    G = tr_set.graph\n\n    e = len(G.edges)\n    n = len(G.nodes)\n    d_l = tr_set.features.shape[1]\n    is_multilabel = False\n    n_classes = tr_set.num_labels\n    node_labels = torch.tensor(tr_set.features)\n    targets = torch.tensor(tr_set.labels)\n    idx_train = torch.BoolTensor(tr_set.train_mask)  # in this case, there are msk => convert to boolean mask\n    idx_valid = torch.BoolTensor(tr_set.val_mask)\n    idx_test = torch.BoolTensor(tr_set.test_mask)\n    edges, agg_matrix = nx_to_format(G, aggregation_type, sparse_matrix)\n\n    return Dataset(\n        \"cora\",\n        n,\n        e,\n        d_l,\n        is_multilabel,\n        n_classes,\n        edges,\n        agg_matrix,\n        node_labels,\n        targets,\n        idx_train,\n        idx_valid,\n        idx_test,\n    )\n\n\ndef get_dgl_citation(aggregation_type=\"sum\", dataset=\"pubmed\"):\n    import dgl\n    from dgl.data import CitationGraphDataset\n\n    tr_set = CitationGraphDataset(dataset)\n    G = tr_set.graph\n\n    e = len(G.edges)\n    n = len(G.nodes)\n    d_l = tr_set.features.shape[1]\n    is_multilabel = False\n    n_classes = tr_set.num_labels\n    node_labels = torch.tensor(tr_set.features)\n    targets = torch.tensor(tr_set.labels)\n    idx_train = torch.BoolTensor(tr_set.train_mask)\n    idx_valid = torch.BoolTensor(tr_set.val_mask)\n    idx_test = torch.BoolTensor(tr_set.test_mask)\n    edges, agg_matrix = nx_to_format(G, aggregation_type)\n\n    return Dataset(\n        \"cora\",\n        n,\n        e,\n        d_l,\n        is_multilabel,\n        n_classes,\n        edges,\n        agg_matrix,\n        node_labels,\n        targets,\n        idx_train,\n        idx_valid,\n        idx_test,\n    )\n\n\ndef get_dgl_karate(aggregation_type=\"sum\"):\n    import dgl\n    from dgl.data import KarateClub\n\n    tr_set = KarateClub()\n    G = tr_set.graph\n\n    e = len(G.edges)\n    n = len(G.nodes)\n    d_l = tr_set.features.shape[1]\n    is_multilabel = False\n    n_classes = tr_set.num_labels\n    node_labels = torch.tensor(tr_set.features)\n    targets = torch.tensor(tr_set.labels)\n    idx_train = torch.BoolTensor(tr_set.train_mask)\n    idx_valid = torch.BoolTensor(tr_set.val_mask)\n    idx_test = torch.BoolTensor(tr_set.test_mask)\n    edges, agg_matrix = nx_to_format(G, aggregation_type)\n\n    return Dataset(\n        \"cora\",\n        n,\n        e,\n        d_l,\n        is_multilabel,\n        n_classes,\n        edges,\n        agg_matrix,\n        node_labels,\n        targets,\n        idx_train,\n        idx_valid,\n        idx_test,\n    )\n\n\ndef from_EN_to_GNN(E, N, targets, aggregation_type, sparse_matrix=True):\n    \"\"\"\n    :param E: # E matrix - matrix of edges : [[id_p, id_c, graph_id],...]\n    :param N: # N matrix - [node_features, graph_id (to which the node belongs)]\n    :return: # L matrix - list of graph targets [tar_g_1, tar_g_2, ...]\n    \"\"\"\n\n    N_full = N\n    E_full = E\n    N = N[:, :-1]  # avoid graph_id\n    e = E[:, :2]  # take only first tow columns => id_p, id_c\n\n    # creating input for gnn => [id_p, id_c, label_p, label_c]\n\n    # creating arcnode matrix, but transposed\n    \"\"\"\n    1 1 0 0 0 0 0 \n    0 0 1 1 0 0 0\n    0 0 0 0 1 1 1    \n\n    \"\"\"  # for the indices where to insert the ones, stack the id_p and the column id (single 1 for column)\n    G = nx.DiGraph()\n    G.add_nodes_from(range(0, np.max(e) + 1))\n    G.add_edges_from(e)\n    edges, agg_matrix = nx_to_format(G, aggregation_type, sparse_matrix)\n\n    # get the number of graphs => from the graph_id\n    num_graphs = int(max(N_full[:, -1]) + 1)\n    # get all graph_ids\n    g_ids = N_full[:, -1]\n    g_ids = g_ids.astype(np.int32)\n\n    # creating graphnode matrix => create identity matrix get row corresponding to id of the graph\n    # graphnode = np.take(np.eye(num_graphs), g_ids, axis=0).T\n    # substitued with same code as before\n    if sparse_matrix:\n        unique, counts = np.unique(g_ids, return_counts=True)\n        values_matrix = np.ones([len(g_ids)]).astype(np.float32)\n        if aggregation_type == \"degreenorm\":\n            values_matrix_normalized = values_matrix[g_ids] / counts[g_ids]\n        else:\n            values_matrix_normalized = values_matrix\n        # graphnode = SparseMatrix(indices=np.stack((g_ids, np.arange(len(g_ids))), axis=1),\n        #                          values=np.ones([len(g_ids)]).astype(np.float32),\n        #                          dense_shape=[num_graphs, len(N)])\n\n        agg_matrix_i = torch.LongTensor([g_ids, list(range(len(g_ids)))])\n        agg_matrix_v = torch.FloatTensor(values_matrix_normalized)\n        graphnode = torch.sparse.FloatTensor(agg_matrix_i, agg_matrix_v, torch.Size([num_graphs, len(N)]))\n    else:\n        graphnode = torch.tensor(np.take(np.eye(num_graphs), g_ids, axis=0).T)\n    # print(graphnode.shape)\n\n    e = E_full.shape[0]\n    n = N_full.shape[0]\n    d_l = N.shape[1]\n    is_multilabel = False\n    n_classes = (np.max(targets).astype(np.int) + 1)\n    node_labels = torch.FloatTensor(N)\n    targets = torch.tensor(targets, dtype=torch.long)\n    return Dataset(\n        \"name\",\n        n,\n        e,\n        d_l,\n        is_multilabel,\n        n_classes,\n        edges,\n        agg_matrix,\n        node_labels,\n        targets,\n        graph_node=graphnode\n    )\n\n\n\ndef old_load_karate(path=\"data/karate/\"):\n    \"\"\"Load karate club dataset\"\"\"\n    print('Loading karate club dataset...')\n    import random\n    import scipy.sparse as sp\n\n    edges = np.loadtxt(\"{}edges.txt\".format(path), dtype=np.int32)  # 0-based indexing\n\n    # edge_inv = np.flip(edges, axis=1) # add also archs in opposite direction\n    # edges = np.concatenate((edges, edge_inv))\n    edges = edges[np.lexsort((edges[:, 1], edges[:, 0]))]  # reorder list of edges also by second column\n    features = sp.eye(np.max(edges+1), dtype=np.float).tocsr()\n\n    idx_labels = np.loadtxt(\"{}classes.txt\".format(path), dtype=np.float32)\n    idx_labels = idx_labels[idx_labels[:, 0].argsort()]\n\n    labels = idx_labels[:, 1]\n    #labels = np.eye(max(idx_labels[:, 1])+1, dtype=np.int32)[idx_labels[:, 1]]  # one-hot encoding of labels\n\n    E = np.concatenate((edges, np.zeros((len(edges), 1), dtype=np.int32)), axis=1)\n    N = np.concatenate((features.toarray(), np.zeros((features.shape[0], 1), dtype=np.int32)), axis=1)\n\n    mask_train = np.zeros(shape=(34,), dtype=np.float32)\n\n    id_0, id_4, id_5, id_12 = random.choices(np.argwhere(labels == 0), k=4)\n    id_1, id_6, id_7, id_13 = random.choices(np.argwhere(labels == 1), k=4)\n    id_2, id_8, id_9, id_14 = random.choices(np.argwhere(labels == 2), k=4)\n    id_3, id_10, id_11, id_15 = random.choices(np.argwhere(labels == 3), k=4)\n\n    mask_train[id_0] = 1.  # class 1\n    mask_train[id_1] = 1.  # class 2\n    mask_train[id_2] = 1.  # class 0\n    mask_train[id_3] = 1.  # class 3\n\n    mask_test = 1. - mask_train\n\n    return E, N, labels,  torch.BoolTensor(mask_train),  torch.BoolTensor(mask_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}