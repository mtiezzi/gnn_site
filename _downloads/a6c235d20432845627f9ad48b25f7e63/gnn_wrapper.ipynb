{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Model Wrapper\n\nThis is the model wrapper file for the PyTorch implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport dataloader\nimport torch.optim as optim\nfrom abc import ABCMeta, abstractmethod\nfrom utils import Accuracy\nfrom torch.utils.tensorboard import SummaryWriter\nimport torchvision\nfrom utils import matplotlib_imshow\nimport utils\nfrom pygnn import GNN\n\n\nclass GNNWrapper:\n    class Config:\n        def __init__(self):\n            self.device = None\n            self.use_cuda = None\n            self.dataset_path = None\n            self.log_interval = None\n            self.tensorboard = None\n            self.task_type = None\n\n            # hyperparams\n            self.lrw = None\n            self.loss_f = None\n            self.epochs = None\n            self.convergence_threshold = None\n            self.max_iterations = None\n            self.n_nodes = None\n            self.state_dim = None\n            self.label_dim = None\n            self.output_dim = None\n            self.graph_based = False\n            self.activation = torch.nn.Tanh()\n            self.state_transition_hidden_dims = None\n            self.output_function_hidden_dims = None\n            self.task_type = \"semisupervised\"\n\n            # optional\n            # self.loss_w = 1.\n            # self.energy_weight = 0.\n            # self.l2_weight = 0.\n\n    def __init__(self, config: Config):\n        self.config = config\n\n        # to be populated\n        self.optimizer = None\n        self.criterion = None\n        self.train_loader = None\n        self.test_loader = None\n\n        if self.config.tensorboard:\n            self.writer = SummaryWriter('logs/tensorboard')\n        self.first_flag_writer = True\n\n    def __call__(self, dset, state_net=None, out_net=None):\n        # handle the dataset info\n        self._data_loader(dset)\n        self.gnn = GNN(self.config, state_net, out_net).to(self.config.device)\n        self._criterion()\n        self._optimizer()\n        self._accuracy()\n\n    def _data_loader(self, dset):  # handle dataset data and metadata\n        self.dset = dset.to(self.config.device)\n        self.config.label_dim = self.dset.node_label_dim\n        self.config.n_nodes = self.dset.num_nodes\n        self.config.output_dim = self.dset.num_classes\n\n    def _optimizer(self):\n        # for name, param in self.gnn.named_parameters():\n        #     if param.requires_grad:\n        #         print(name, param.data)\n        # exit()\n        self.optimizer = optim.Adam(self.gnn.parameters(), lr=self.config.lrw)\n        #self.optimizer = optim.SGD(self.gnn.parameters(), lr=self.config.lrw)\n\n    def _criterion(self):\n        self.criterion = nn.CrossEntropyLoss()\n\n    def _accuracy(self):\n        self.TrainAccuracy = Accuracy(type=self.config.task_type)\n        self.ValidAccuracy = Accuracy(type=self.config.task_type)\n        self.TestAccuracy = Accuracy(type=self.config.task_type)\n\n    def train_step(self, epoch):\n        self.gnn.train()\n        data = self.dset\n        self.optimizer.zero_grad()\n        self.TrainAccuracy.reset()\n        # output computation\n        output, iterations = self.gnn(data.edges, data.agg_matrix, data.node_labels)\n        # loss computation - semisupervised\n        loss = self.criterion(output, data.targets)\n\n        loss.backward()\n\n        self.optimizer.step()\n\n        # # updating accuracy\n        # batch_acc = self.TrainAccuracy.update((output, target), batch_compute=True)\n        with torch.no_grad():  # Accuracy computation\n            # accuracy_train = torch.mean(\n            #     (torch.argmax(output[data.idx_train], dim=-1) == data.targets[data.idx_train]).float())\n            self.TrainAccuracy.update(output, data.targets)\n            accuracy_train = self.TrainAccuracy.compute()\n\n            if epoch % self.config.log_interval == 0:\n                print(\n                    'Train Epoch: {} \\t Mean Loss: {:.6f}\\tAccuracy Full Batch: {:.6f} \\t  Best Accuracy : {:.6f}  \\t Iterations: {}'.format(\n                        epoch, loss, accuracy_train, self.TrainAccuracy.get_best(), iterations))\n\n                if self.config.tensorboard:\n                    self.writer.add_scalar('Training Accuracy',\n                                           accuracy_train,\n                                           epoch)\n                    self.writer.add_scalar('Training Loss',\n                                           loss,\n                                           epoch)\n                    self.writer.add_scalar('Training Iterations',\n                                           iterations,\n                                           epoch)\n\n                    for name, param in self.gnn.named_parameters():\n                        self.writer.add_histogram(name, param, epoch)\n        # self.TrainAccuracy.reset()\n\n    def predict(self, edges, agg_matrix, node_labels):\n        return self.gnn(edges, agg_matrix, node_labels)\n\n    def test_step(self, epoch):\n        ####  TEST\n        self.gnn.eval()\n        data = self.dset\n        self.TestAccuracy.reset()\n        with torch.no_grad():\n            output, iterations = self.gnn(data.edges, data.agg_matrix, data.node_labels)\n            test_loss = self.criterion(output, data.targets)\n\n            self.TestAccuracy.update(output, data.targets)\n            acc_test = self.TestAccuracy.compute()\n            # acc_test = torch.mean(\n            #     (torch.argmax(output[data.idx_test], dim=-1) == data.targets[data.idx_test]).float())\n\n            if epoch % self.config.log_interval == 0:\n                print('Test set: Average loss: {:.4f}, Accuracy:  ({:.4f}%) , Best Accuracy:  ({:.4f}%)'.format(\n                    test_loss, acc_test, self.TestAccuracy.get_best()))\n\n                if self.config.tensorboard:\n                    self.writer.add_scalar('Test Accuracy',\n                                           acc_test,\n                                           epoch)\n                    self.writer.add_scalar('Test Loss',\n                                           test_loss,\n                                           epoch)\n                    self.writer.add_scalar('Test Iterations',\n                                           iterations,\n                                           epoch)\n\n    def valid_step(self, epoch):\n        ####  TEST\n        self.gnn.eval()\n        data = self.dset\n        self.ValidAccuracy.reset()\n        with torch.no_grad():\n            output, iterations = self.gnn(data.edges, data.agg_matrix, data.node_labels)\n            test_loss = self.criterion(output, data.targets)\n\n            self.ValidAccuracy.update(output, data.targets)\n            acc_valid = self.ValidAccuracy.compute()\n            # acc_test = torch.mean(\n            #     (torch.argmax(output[data.idx_test], dim=-1) == data.targets[data.idx_test]).float())\n\n            if epoch % self.config.log_interval == 0:\n                print('Valid set: Average loss: {:.4f}, Accuracy:  ({:.4f}%) , Best Accuracy:  ({:.4f}%)'.format(\n                    test_loss, acc_valid, self.ValidAccuracy.get_best()))\n\n                if self.config.tensorboard:\n                    self.writer.add_scalar('Valid Accuracy',\n                                           acc_valid,\n                                           epoch)\n                    self.writer.add_scalar('Valid Loss',\n                                           test_loss,\n                                           epoch)\n                    self.writer.add_scalar('Valid Iterations',\n                                           iterations,\n                                           epoch)\n\n\nclass SemiSupGNNWrapper(GNNWrapper):\n    class Config:\n        def __init__(self):\n            self.device = None\n            self.use_cuda = None\n            self.dataset_path = None\n            self.log_interval = None\n            self.tensorboard = None\n            self.task_type = None\n\n            # hyperparams\n            self.lrw = None\n            self.loss_f = None\n            self.epochs = None\n            self.convergence_threshold = None\n            self.max_iterations = None\n            self.n_nodes = None\n            self.state_dim = None\n            self.label_dim = None\n            self.output_dim = None\n            self.graph_based = False\n            self.activation = torch.nn.Tanh()\n            self.state_transition_hidden_dims = None\n            self.output_function_hidden_dims = None\n\n            # optional\n            # self.loss_w = 1.\n            # self.energy_weight = 0.\n            # self.l2_weight = 0.\n\n    def __init__(self, config: Config):\n        super().__init__(config)\n\n    def _data_loader(self, dset):  # handle dataset data and metadata\n        self.dset = dset.to(self.config.device)\n        self.config.label_dim = self.dset.node_label_dim\n        self.config.n_nodes = self.dset.num_nodes\n        self.config.output_dim = self.dset.num_classes\n\n    def _accuracy(self):\n        self.TrainAccuracy = Accuracy(type=\"semisupervised\")\n        self.ValidAccuracy = Accuracy(type=\"semisupervised\")\n        self.TestAccuracy = Accuracy(type=\"semisupervised\")\n\n    def train_step(self, epoch):\n        self.gnn.train()\n        data = self.dset\n        self.optimizer.zero_grad()\n        self.TrainAccuracy.reset()\n        # output computation\n        output, iterations = self.gnn(data.edges, data.agg_matrix, data.node_labels)\n        # loss computation - semisupervised\n        loss = self.criterion(output[data.idx_train], data.targets[data.idx_train])\n\n        loss.backward()\n\n        # with torch.no_grad():\n        #     for name, param in self.gnn.named_parameters():\n        #         if \"state_transition_function\" in name:\n        #             #self.writer.add_histogram(\"gradient \" + name, param.grad, epoch)\n        #             param.grad = 0*  param.grad\n\n\n\n        self.optimizer.step()\n\n        # # updating accuracy\n        # batch_acc = self.TrainAccuracy.update((output, target), batch_compute=True)\n        with torch.no_grad():  # Accuracy computation\n            # accuracy_train = torch.mean(\n            #     (torch.argmax(output[data.idx_train], dim=-1) == data.targets[data.idx_train]).float())\n            self.TrainAccuracy.update(output, data.targets, idx=data.idx_train)\n            accuracy_train = self.TrainAccuracy.compute()\n\n            if epoch % self.config.log_interval == 0:\n                print(\n                    'Train Epoch: {} \\t Mean Loss: {:.6f}\\tAccuracy Full Batch: {:.6f} \\t  Best Accuracy : {:.6f}  \\t Iterations: {}'.format(\n                        epoch, loss, accuracy_train, self.TrainAccuracy.get_best(), iterations))\n\n                if self.config.tensorboard:\n                    self.writer.add_scalar('Training Accuracy',\n                                           accuracy_train,\n                                           epoch)\n                    self.writer.add_scalar('Training Loss',\n                                           loss,\n                                           epoch)\n                    self.writer.add_scalar('Training Iterations',\n                                           iterations,\n                                           epoch)\n                    for name, param in self.gnn.named_parameters():\n                        self.writer.add_histogram(name, param, epoch)\n                        self.writer.add_histogram(\"gradient \" + name, param.grad, epoch)\n        # self.TrainAccuracy.reset()\n        return output # used for plotting\n\n    def predict(self, edges, agg_matrix, node_labels):\n        return self.gnn(edges, agg_matrix, node_labels)\n\n    def test_step(self, epoch):\n        ####  TEST\n        self.gnn.eval()\n        data = self.dset\n        self.TestAccuracy.reset()\n        with torch.no_grad():\n            output, iterations = self.gnn(data.edges, data.agg_matrix, data.node_labels)\n            test_loss = self.criterion(output[data.idx_test], data.targets[data.idx_test])\n\n            self.TestAccuracy.update(output, data.targets, idx=data.idx_test)\n            acc_test = self.TestAccuracy.compute()\n            # acc_test = torch.mean(\n            #     (torch.argmax(output[data.idx_test], dim=-1) == data.targets[data.idx_test]).float())\n\n            if epoch % self.config.log_interval == 0:\n                print('Test set: Average loss: {:.4f}, Accuracy:  ({:.4f}%) , Best Accuracy:  ({:.4f}%)'.format(\n                    test_loss, acc_test, self.TestAccuracy.get_best()))\n\n                if self.config.tensorboard:\n                    self.writer.add_scalar('Test Accuracy',\n                                           acc_test,\n                                           epoch)\n                    self.writer.add_scalar('Test Loss',\n                                           test_loss,\n                                           epoch)\n                    self.writer.add_scalar('Test Iterations',\n                                           iterations,\n                                           epoch)\n\n    def valid_step(self, epoch):\n        ####  TEST\n        self.gnn.eval()\n        data = self.dset\n        self.ValidAccuracy.reset()\n        with torch.no_grad():\n            output, iterations = self.gnn(data.edges, data.agg_matrix, data.node_labels)\n            test_loss = self.criterion(output[data.idx_valid], data.targets[data.idx_valid])\n\n            self.ValidAccuracy.update(output, data.targets, idx=data.idx_valid)\n            acc_valid = self.ValidAccuracy.compute()\n            # acc_test = torch.mean(\n            #     (torch.argmax(output[data.idx_test], dim=-1) == data.targets[data.idx_test]).float())\n\n            if epoch % self.config.log_interval == 0:\n                print('Valid set: Average loss: {:.4f}, Accuracy:  ({:.4f}%) , Best Accuracy:  ({:.4f}%)'.format(\n                    test_loss, acc_valid, self.ValidAccuracy.get_best()))\n\n                if self.config.tensorboard:\n                    self.writer.add_scalar('Valid Accuracy',\n                                           acc_valid,\n                                           epoch)\n                    self.writer.add_scalar('Valid Loss',\n                                           test_loss,\n                                           epoch)\n                    self.writer.add_scalar('Valid Iterations',\n                                           iterations,\n                                           epoch)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}