{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Utils\n\nThis is the utils file for the PyTorch implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom abc import ABCMeta, abstractmethod\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch.nn.functional as F\nimport torchvision\n\n\ndef prepare_device(n_gpu_use, gpu_id=None):\n    \"\"\"\n    setup specific GPU device if available, move model into configured device\n    \"\"\"\n    n_gpu = torch.cuda.device_count()\n    if n_gpu_use > 0 and n_gpu == 0:\n        print(\"Warning: There\\'s no GPU available on this machine,\"\n              \"training will be performed on CPU.\")\n        n_gpu_use = 0\n    if n_gpu_use > n_gpu:\n        print(\"Warning: The number of GPU\\'s configured to use is {}, but only {} are available \"\n              \"on this machine.\".format(n_gpu_use, n_gpu))\n        n_gpu_use = n_gpu\n    device = torch.device('cuda:{}'.format(gpu_id) if n_gpu_use > 0 else 'cpu')\n    print(\"Executing on device: \", device)\n    return device\n\n\nclass Metric:\n    def __init__(self):\n        self.reset()\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"\n        Resets the metric to it's initial state.\n\n        This is called at the start of each epoch.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def update(self, output, target):\n        \"\"\"\n        Updates the metric's state using the passed batch output.\n\n        This is called once for each batch.\n\n        Args:\n            output: the is the output from the engine's process function.\n            target: target to match\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def compute(self):\n        \"\"\"\n        Computes the metric based on it's accumulated state.\n\n        This is called at the end of each epoch.\n\n        Returns:\n            Any: the actual quantity of interest.\n\n        Raises:\n            NotComputableError: raised when the metric cannot be computed.\n        \"\"\"\n        pass\n\n\nclass Accuracy(Metric):\n\n    def __init__(self, is_multilabel=False, type=None):\n        self._is_multilabel = is_multilabel\n        self._type = type\n        # self._num_classes = None\n        self._num_correct = None\n        self._num_examples = None\n        self.best_accuracy = -1\n        super(Accuracy, self).__init__()\n\n    def reset(self):\n        # self._num_classes = None\n        self._num_correct = 0\n        self._num_examples = 0\n        super(Accuracy, self).reset()\n\n    def update(self, output, target, batch_compute=False, idx=None):\n        y_pred = output\n\n        if self._type == \"binary\":\n            correct = torch.eq(y_pred.view(-1).to(target), target.view(-1))\n        elif self._type == \"multiclass\":\n            pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct = pred.eq(target.view_as(pred))\n            if batch_compute:\n                batch_dim = correct.shape[0]\n                batch_accuracy = torch.sum(correct).item() / batch_dim\n\n        if self._type == \"multilabel\":\n            # if y, y_pred shape is (N, C, ...) -> (N x ..., C)\n            num_classes = y_pred.size(1)\n            last_dim = y_pred.ndimension()\n            y_pred = torch.transpose(y_pred, 1, last_dim - 1).reshape(-1, num_classes)\n            target = torch.transpose(target, 1, last_dim - 1).reshape(-1, num_classes)\n            correct = torch.all(target == y_pred.type_as(target), dim=-1)\n        elif self._type == \"semisupervised\":\n            target = target[idx]\n            y_pred = y_pred[idx]\n            pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n            correct = pred.eq(target.view_as(pred))\n\n        # elif self._type == \"semisupervised\":\n        #     output[data.idx_test], data.targets[data.idx_test]\n        self._num_correct += torch.sum(correct).item()\n        self._num_examples += correct.shape[0]\n\n        if batch_compute:\n            return batch_accuracy\n\n    def get_best(self):\n        return self.best_accuracy\n\n    def compute(self):\n        if self._num_examples == 0:\n            raise Exception('Accuracy must have at least one example before it can be computed.')\n        acc = self._num_correct / self._num_examples\n        if acc > self.best_accuracy:\n            self.best_accuracy = acc\n        return self._num_correct / self._num_examples\n\n\ndef matplotlib_imshow(img, one_channel=False):\n    if one_channel:\n        img = img.mean(dim=0)\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    if one_channel:\n        plt.imshow(npimg, cmap=\"Greys\")\n    else:\n        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n\ndef __weights_visualizer(self, layer, name, epoch):\n    # reshape filter >= firset dimension used as a batch, so we can see all filters\n    visualize = layer.mu.view(layer.in_channels * layer.out_channels, 1,\n                              layer.kernel_size[0], layer.kernel_size[1])\n    # resize in b x 1 x w x h (1 channel)\n    vis_grid = torchvision.utils.make_grid(visualize.cpu())\n    self.writer.add_image(name, vis_grid, global_step=epoch)\n\n\ndef get_G_function(descr, eps):\n    GF = descr\n    if GF == \"lin\":\n        def G(x):\n            return x\n    elif GF == \"abs\":\n        def G(x):\n            return torch.abs(x)\n    elif GF == \"eps\":\n        def G(x):\n            return F.relu(torch.abs(x) - eps)\n    elif GF == \"lineps\":\n        def G(x):\n            return F.relu(x - eps) - F.relu(- x - eps)\n    elif GF == \"squared\":\n        def G(x):\n            return torch.pow(x, 2)\n    elif GF == \"^3\":\n        def G(x):\n            return torch.pow(x, 3)\n    else:\n        def G(x):\n            return x\n    return G"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}